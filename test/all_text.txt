"我是今天发布会的主持人陈佳佳。""尊敬的各位领导、来宾，现场的媒体朋友们，大家上午好。欢迎来到AI引领智取新城西湖论剑及安肯西西年度新品发布会现场。""首先，我介绍来自行业及投资机构的嘉宾代表，他们是北京赛博英杰科技有限公司创始人谭晓生，欢迎您。""浙商银行首席风险官、科技部副总骆建，欢迎您；杭州银行科技部沈琴，欢迎您；万家基金黄兴亮，欢迎您。""参加本次发布会的安可信息相关领导有：安可信息董事长范渊，安全信息CTO刘博，安可信息CSO袁明坤，CC CMO黄安培，CC CEO郑州，安可信息高级副总裁刘志乐和杨博。注意，\"uncle\"和\"安凯\"在列表中似乎是误报或重复，且\"CC cmo\"和\"CCCEO\"应分别修正为\"CC CMO\"和\"CC CEO\"，同时为了保持列表的清晰和一致，将\"安可信息\"的前缀在重复提及时省略。""信息研究院院长王鑫、安培信息高级副总裁冯旭航、安培信息高级副总裁邓平霞、安凯兮兮董事会秘书曝恒，以及各位来自媒体界的朋友们，欢迎你们的到来。八年前的今天，习近平总书记主持召开网络安全和信息化工作座谈会，为我国的网络安全和信息化事业的繁荣描绘了广阔的前景。""在总书记419讲话的指引下，安全信息在防止安全和数字化的洪流中勇往直前，以创新为方向，稳健前行。""接下来，我们迎来了安肯信息年度新品防火墙全系增强发布，有请安肯信息基础安全产品线总裁何孔。""自去年起，我们已连续两年举办419新品发布会，积极展示并实践网络安全与心智生产力。防火墙作为安全的第一道防线，与AI结合将产生怎样的效果？""尊敬的各位领导嘉宾，大家好，我是安安，信息安全产线的合同专员。""下面我向大家汇报我们在防火墙和AI融合方面增强的一些发布的功能。我们知道防火墙实际上是一个历史非常长的产品。""随着AI的发展，黑产在流量侧用AI进行攻击的现象早已出现。因此，防火墙的发展脉络核心需求在于流量变化带来的安全防护变化，我们的防火墙功能需相应调整。""防火墙经过研究，我们发现它不足以完全承接AI的效果。以防火墙为例，它就像家里的智能门锁。""最初，门锁通过指纹识别家人，后来增加了智能摄像头，并与家中其他安全设施联动。最近，它还能通过云端进行运营。我相信将来会出现家用门锁，能通过云端安全中心为客户提供家庭安全运营服务。""防火墙也是一样，我们做了一些分层设计。首先在设备侧，接近客户这一侧，我们通过小模型加协同的方式实现安全功能。""在这个终端，我们的数据平台侧，我们通过防火墙和协同的数据传到优秀的企业级安全管理平台，进行全方位的安全分析。包括威胁分析、日志归并、告警去重等工作。""在云端，我们主要使用大模型和情报深化设备侧的处置与分析，进行深层次赋能，同时下发处置和联动动作，这是我们的分层设计。相应地，我们在防火墙产品架构上也做了一些改进。""第三个是防火墙，它涵盖高中低端，包括家庭桌面端。""主要解决的问题有几点难点：一是防火墙的硬件AI能力有限，因此我们主要在外部进行数据训练，防火墙上执行AI推理。二是防火墙作为流量型产品，对时间要求极高，我们通过大量工程化代码加速和优化，将检测时延降至微秒级别。""我们需要让AI算法支持异构硬件，这是我们AI架构设计的重点。第二部分，我将简要汇报我们在高级检测上的增强。""举例子来讲，我们通过GRU神经网络，利用1.3亿以上的数据学习，能够识别70类以上的DJA黑产家族，有效规避僵尸主机违规外联问题。在高级规避性威胁防御方面，特别是针对DNS的隐蔽信道，包括C2外联和隐秘数据泄露，我们有相应对策。""我们使用了K0算法进行了一些持续学习。""在应对恶意流量加密时，基于流量基线，我们结合了传统方法以增强检测效果。这实现了一条技术路线，主要分两步：首先，在外部，我们利用大量数据进行训练。""这个主要涉及决策类神经网络和深度学习模型，我们会获得一些分类器。完成这项工作后，我们将进行代码转换和设备侧代码框架加速。目标是解决异构硬件问题，实现对恶意流量的快速准确检测。""我们也有一些优势，一年前对原有模型做了大量更新。目前的优势如下：第一个，我们更新了学习模型，开销小，时间也更短。""第二个是我们数据量的增大，包括数据训练的数据筛选和参数调优，我们做了大量工作。目前，我们在白样本误报率和黑样本漏报率方面的指标在业内是领先的。""第三，我们覆盖的样本家族种类更多，覆盖面更广，这是我们的优势。此外，我们使用情报辅助强化了出站安全。从技术角度讲，AI能解决大量新型AI黑产问题。""它并不是一个完整的解决方案，在AI基础上，最有用的是我们还要辅助情报的能力。""举例子来讲，很多黑产有家族特征，但一些隐秘的APD攻击，使用人工生成的域名和IP，这需要我们的情报能力来补充。结合这两点，我们可以实现接近百分之百的检测率。""我们今年在以往出战情报入栈情报的基础上，强化了出栈的安全。""这块主要是能够增强客户在进行安全加固时，达到这样一个效果。""我们出站安全，简单来讲，主要对内网APP挖矿、钓鱼、木马等检测有效，这是情报方面的增强。在情报这块，我们新增了热点事件的推送能力。""最后一部分，我简单介绍一下防火墙安全运营方面的增强。我们引入了阿凡达，在大模型框架加持下，给防火墙内置了两个AI小助手，小恒和小安。注意，此处将“阿凡提”修正为更符合语境的“阿凡达”。""我们知道防火墙是一个比较复杂的产品，传统的运营和运维确实非常困难。对于客户而言，查询也较为麻烦。我们采用自然语言作为接口，以对话方式提供个性化配置指南和帮助，让客户能更轻松地进行操作。""小安主要负责售后咨询，专注于复杂场景的配置、功能查询以及日志分析解读。小恒则主要进行问题诊断。""恶意代码检测、威胁情报分析，协助用户完成异常事件解读、告警深度分析、策略分析等工作。最后，介绍一下防火墙的一体化安全运维。安全运营方面，防火墙经历了几十年的发展。""从单体角度看，未来的发展空间有限。要进化到下一代真正智能的防火墙，必须在一体化安全运营和体系化的AI体系中发挥作用。""我们的防火墙目前应该是处于部署阶段，实现了与平台和周边产品的良好联动与对接。""通过这样的协同，我们能够打通数据日志分析和处置的整个流程，并充分发挥安全产品每种类型、每个层次的特点和优势。从而，我们能为用户提供防火墙一体化的MS云托管服务。""如果客户在节假日希望将防火墙托管到云端，可以使用安恒的MS云托管服务。""我们会有专人帮助客户运营。最后，我想讲一下我对防火墙的认知。防火墙作为一个传统产品，我相信它的未来会走向云端和智能，我期待这一天快速到来。""有一个统一且真正强大的通用安全智能在云端，它能将防火墙、我们的平台和周边产品理解和协同起来，实现真正的运营。""为客户解决未来的安全问题，感谢大家，感谢何孔总。去年，我们致力于让安全更智能，让智能更安全。在大数据和AI时代，保护大模型训练和推理过程中的数据安全至关重要。""接下来，安恒信息隐私计算产品总监陶立峰将介绍面向大模型训练和推理数据保护的机密计算产品。尊敬的各位领导、来宾，大家中午好。之前的会议内容非常充实和详实。""到了我这一块，我将简短明了地分享汇报内容，不占用大家的午休时间。我的汇报主题是面向大模型训练和推理的数据保护机密计算产品。""这个名字听起来有点拗口，但通过几个简短场景，我来给大家讲清楚。""我要汇报的内容是，在大模型训练的场景下，如果需要整合多方数据，例如以医疗健康大模型训练为例，涉及医院、医保、疾控和药剂等多方数据，我们需要考虑的是，将这些数据集中在哪里进行训练最为合适。""如果在任何地方进行训练，其他方都会担心数据安全，因为数据外泄可能导致失控或被窃取。""您提到的第二个场景，我们需要详细讨论如何优化我们的网络安全策略，特别是在面对日益增长的网络威胁时。我们将评估现有的防火墙设置，加密标准，以及我们的应急响应计划，确保我们能够迅速有效地应对任何潜在的安全事件。""我们训练完成的大模型部署问题，尤其是在自身算力不足时，可能需要借助算力中心或超算中心的资源。如果选择在这些中心部署模型，我们必须关注模型的安全性，包括防止模型被窃取、敏感数据泄露以及模型被篡改的风险。""所有这些问题的解决，重点在于第三个问题。在大模型场景下，大家更关注其应用和价值，但我们也需思考训练过程中的潜在风险。大模型训练可能带来的内容风险，实际上已引起大家的广泛关注。""除了内容风险，还可能存在技术风险、合规风险以及操作风险等问题。以Shadow Rate这种攻击为例，它专门针对Read这一机器学习框架进行攻击。通过特定工具，攻击者能获取到所有使用该框架训练的数据，这暴露出数据安全和隐私保护的重大隐患。""我上面列了一些，这个框架被很多国际知名的企业如亚马逊、Netflix和OpenAI采用。这意味着如果存在其他未知的攻击手段，我们的训练框架可能受到攻击。这引发了一个问题：我们的训练数据是否会因此丢失？围绕训练数据安全、模型部署安全和未知风险安全这三块内容，我们目前正探索尝试解决这些风险。""我们的思路是，在原有机密计算的基础上进行大模型训练。这样做的原因在于，隐私计算具备一个广为人知的特性：原始数据不出域，数据可用不可见。隐私计算天生旨在保护数据和隐私。""在隐私计算的基础上，我们拓展了大模型训练能力，从而能够充分保障训练数据和部署模型的安全。""同时，机密计算底层用到的可信执行环境的硬件技术，能够帮助我们防御未知风险。最后这个问题和我们的方案已讲解完毕。接下来，谈一谈我们在机密计算领域的深厚积累，这不是吹牛，而是基于我们在该领域的丰富经验。""最后我们有幸请到了安恒信息研究院创新业务部产品经理李华伟。""他将为我们带来针对性的大模型安全解决方案，有请。""目前我们处于全国第一梯队，甚至可以说是第一名的厂商。在此基础上，我们拓展了大模型训练的能力。相信在隐私计算领域及未来的大模型训练领域，我们一定能够走得更远，更加坚实。谢谢大家。""各位领导、各位来宾、各位同事，大家中午好。我是安徽信息中央研究院的李华伟。""今天很高兴跟大家分享安恒在大模型安全方面的探索和实践。讨论安全之前，先谈风险。大模型作为新生事物，面临的主要风险包括数据安全、内容安全、意识形态问题及网络犯罪。数据安全方面，大家都有深刻体会。""大模型问世后，数据泄露问题频出，同时产生了内容谣言。其主要问题源于汉语语料不足，尤其在境外开源大模型中，汉语语料占比过低，有时甚至不足1%。""再一个就是网络犯罪问题，大语言模型强大的生成能力可能生成恶意代码。从模型生命周期看，主要分为模型训练、部署和运营三个阶段。""模型训练前，我们需要准备的资源和数据包括：充足的计算资源、开源深度学习框架、各类工具、互联网数据及企业自有数据。模型部署时，重点防范模型泄露风险。模型运营则涉及模型安全，包括防止模型被破解的风险，以及确保模型稳定性。""还有就是关注模型的内容安全。""从应用视角看，模型最关键的内容风险在于，正常推理服务过程中，供应链的安全风险会在模型应用中体现。""模型的数据泄露问题和网络安全风险，我们安恒对大模型安全风险的理解，可从模型训练、部署和运营三方面描述。""训练阶段主要关注供应链安全、数据安全和算法安全合规。部署阶段，我们针对泄露风险和篡改风险实施防护。模型运营阶段，重点是检测内容安全风险。""我们探讨如何检测所提供的大模型安全服务，确保其安全且合规。""第二个是传统网络安全风险，将大模型视为IT信息化系统，它面临的网络安全问题也需要解决。安恒的大模型安全解决方案框架分为五个部分，首要是传统安全防护，安恒信息提供全面的解决方案。""比如说编辑安全、流量安全、EDR等，以及态势和资产安全的产品来防护我们的传统安全边界。运维服务，即我们MMSS的运维。模型训练阶段，主要保障语料库的安全。""包括对训练样本的清洗和投入样本的检测，以及供应链安全检测。法律合规需提前约束。模型防泄漏可采用加密、水印和数字签名等方式，以保障数据安全。""我们提供内容安全评估服务，对模型的输入输出进行全面检测。以适应人工智能在线管理办法及人工智能服务安全基本要求，确保合规。我们具备模型输入和输出检测能力，确保在输入过程，即提示词阶段的安全性。""一些恶意的提示词可以被拦截到。""再者，我们将对模型输出的内容进行二次检测。重点讲解相关安全框架，以及安恒已有产品与之的对应关系。从整体视角看，可分为训练阶段和推理阶段两个部分。""训练阶段偏重于供应链安全、数据安全及语料安全。我们提供语料库安全，包括脱敏系统等服务。""针对大模型训练，有一种观点指出，说明文训练与脱敏处理后，对大模型训练效果的差异。我来解答一下，脱敏处理后对大模型训练的影响很小，特征提取的差异基本控制在3%以内。此外，还涉及多方数据共同训练的场景。""刚才陶总已经提到，我们采用隐私计算平台来保障这个问题。至于大模型的推理，我们提供大模型运营安全的方案，包括风险评估和模型的输入输出安全。""网络环境安全是基础环境安全的一部分。我们提供自动化的安全风险评估服务，使用一个工具接入已有模型进行评估。""我们目前已经对市面上主流的大模型进行了风险评估，评估显示，这些大模型在遵纪守法和品行端正方面表现良好。然而，普遍存在的问题主要是模型幻觉。""也就是说，所答非所问的问题，最严重的就是提示词注入。对于精心构造的提示词，很多通用大模型难以防御。同时，也要警惕新技术沦为犯罪的工具。""关于新技术面临的传统安全风险问题，我们提供一个内容安全引擎。该引擎左侧对接各种外部系统。""然后右侧对接我们的垂域大模型，在外部系统输入之前，引擎会提供检测，针对提示词输入和合规性进行检查。安全的提示词会传递给大模型，但即便如此，大模型仍可能产生不可控内容。我们也可以对输出部分进行检测，以应对这一问题。""这个检测过程不仅涉及关键词匹配，还涵盖了大模型的意图识别能力。总结来说，安恒的大模型安全方案从网络安全、数据安全和内容安全三方面着手，为垂直领域大模型或通用大模型提供安全防护。""我的分享到此结束，感谢大家。感谢华为的精彩分享，请入座。亲爱的各位来宾朋友们，AI令志气兴盛。""今年是西湖论剑第12个年头，恰如一个轮回，新湖论剑将携过往之荣光再起新征程，期待与诸位再会。 ""西湖论剑新品发布会圆满结束，同时预告2024年西湖论剑网络安全大会，诚邀大家于5月17日和18日共聚。"